<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Github+Hexo+nexT 搭建个人博客避坑指南</title>
    <url>/%E4%B8%87%E8%8A%B1%E7%AD%92/Github-Hexo-nexT-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E9%81%BF%E5%9D%91%E6%8C%87%E5%8D%97/</url>
    <content><![CDATA[<p>网上搭建Github+Hexo+nexT搭建个人博客的教程有很多，但是在我个人搭建的过程中还是遇到了不少问题，特此记录，以免更多的人踩坑！</p>
<h2 id="第一个坑：404-File-not-found"><a href="#第一个坑：404-File-not-found" class="headerlink" title="第一个坑：404 File not found"></a>第一个坑：404 File not found</h2><p><img src="https://wx1.sinaimg.cn/mw690/a6facf89ly1ggi9hf1g6hj208c05iaab.jpg" alt="1"></p>
<p>这个坑是我踩到的第一个坑，也是最让人抓狂的一个坑！因为即使使用next的默认设置，home和archives点进去也是404！看着官方文档，一开始以为是因为子目录问题，验证后发现不是。后来以为是版本太新，回滚了一个版本，发现还是不对！后来在知乎上发现了这个<a href="https://www.zhihu.com/question/353097489/answer/888107103" target="_blank" rel="noopener">解决方案</a>, 原来是空格问题：/ || 变成  /||就能解决404问题。在搜索答案的过程中，发现还有一些这样的细节问题，比如冒号后面必须有空格，这些小问题真让人抓狂。</p>
<h2 id="第二个坑：-其它菜单配置问题"><a href="#第二个坑：-其它菜单配置问题" class="headerlink" title="第二个坑： 其它菜单配置问题"></a>第二个坑： 其它菜单配置问题</h2><p>nexT有两个默认的home和archives菜单，但是其它的菜单about、tag等都不是默认的，需要手动配置（如果不配置还是会遇到404问题），但是官网上并没有具体说明。这个后来找到了这个<a href="[https://linlif.github.io/2017/05/27/Hexo%E4%BD%BF%E7%94%A8%E6%94%BB%E7%95%A5-%E6%B7%BB%E5%8A%A0%E5%88%86%E7%B1%BB%E5%8F%8A%E6%A0%87%E7%AD%BE/](https://linlif.github.io/2017/05/27/Hexo使用攻略-添加分类及标签/)">解决方案</a> 去处理，这个坑网上解决方案还是挺多的。</p>
<h2 id="常用的hexo命令"><a href="#常用的hexo命令" class="headerlink" title="常用的hexo命令"></a>常用的hexo命令</h2><ul>
<li>hexo new ‘文章标题’ # 在blog路径下，新建一个md文档创作吧</li>
<li>hexo new draft ‘文章标题’ # 文章暂时不发布，先保存在草稿箱</li>
<li>hexo publish [layout] ‘文章标题’ # 将草稿箱的文章发布出去</li>
<li>hexo clean # 清除缓存文件(db.json)和已生成的静态文件(public)，一般对站点进行更改后（尤其是主题更换），需要运行此命令</li>
<li>hexo g</li>
<li>hexo s</li>
<li>hexo d</li>
<li></li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.jianshu.com/p/9f0e90cc32c2" target="_blank" rel="noopener">动态背景、github关联、文章结束、网站访问量</a></p>
<p><a href="https://www.jianshu.com/p/efbeddc5eb19" target="_blank" rel="noopener">字数统计、更新时间、代码复制、文章加密</a></p>
<p><a href="https://tding.top/archives/ed8b904f.html" target="_blank" rel="noopener">评论</a></p>
<ul>
<li><a href="https://leeguoo.com/" target="_blank" rel="noopener">https://leeguoo.com/</a> 网盘 wiki 搜索添加</li>
<li>配置非常全面的一个文章 <a href="https://io-oi.me/tech/hexo-next-optimization/" target="_blank" rel="noopener">https://io-oi.me/tech/hexo-next-optimization/</a></li>
<li>配置很全 <a href="https://www.simon96.online/2018/10/12/hexo-tutorial/" target="_blank" rel="noopener">https://www.simon96.online/2018/10/12/hexo-tutorial/</a></li>
<li>喜欢这个作者的hexo <a href="https://tding.top/archives/567debe0.html" target="_blank" rel="noopener">https://tding.top/archives/567debe0.html</a></li>
<li><a href="https://www.zhihu.com/question/30911258" target="_blank" rel="noopener">https://www.zhihu.com/question/30911258</a> 知乎上一些有意思的插件</li>
<li>换电脑 请参考这篇文章：<a href="https://formulahendry.github.io/2016/12/04/hexo-ci/" target="_blank" rel="noopener">https://formulahendry.github.io/2016/12/04/hexo-ci/</a></li>
</ul>
<h1 id="通过比例辅助判断，具有这个前项的id，他的后项占比多少"><a href="#通过比例辅助判断，具有这个前项的id，他的后项占比多少" class="headerlink" title="通过比例辅助判断，具有这个前项的id，他的后项占比多少"></a>通过比例辅助判断，具有这个前项的id，他的后项占比多少</h1><p>a  <em>c</em> ac d ab</p>
<p>cd d改成B（并不一定要最小，不然直接是n） <em>B</em> bc ac(改成BCD)</p>
<p>leanCloud XWFaxx163.com</p>
<p>列表拆分多列 <a href="https://blog.csdn.net/u011412768/article/details/94347640" target="_blank" rel="noopener">https://blog.csdn.net/u011412768/article/details/94347640</a></p>
]]></content>
      <categories>
        <category>万花筒</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title>主成分分析-PCA</title>
    <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-PCA/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>PCA</tag>
      </tags>
  </entry>
  <entry>
    <title>聚类</title>
    <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95-kmeans/</url>
    <content><![CDATA[<h2 id="白话k-means算法"><a href="#白话k-means算法" class="headerlink" title="白话k-means算法"></a>白话k-means算法</h2><p>我们常说：物以类聚，人以群分。这个 “类” 和 “群”怎么理解呢？从文字上扣一下：“类”指具有某些<strong>共同性质</strong>的对象。<del>计算机的，“类”是指对现实生活中一类<strong>具有共同特征</strong>的事物的抽象</del>。 “群”本义指牲畜聚合一处，泛指同类相聚。无论是”类“或”群“，他们都带有一些<strong>共同特征</strong>的味道。这在生活中也很常见：相似的人更容易玩到一块儿！</p>
<p>那么从数学上怎么刻画这种相似呢？怎么把相似的事物或人聚到一起呢？聚成几类呢？让我们带着这些疑问一起来看看大名鼎鼎的k-means算法吧！</p>
<p>k-means算法就是将一堆没有打标签的数据集聚类成不同的组（簇）。它的原理还是比较简单的，也比较容易理解。概括来说，就两步：</p>
<p><strong>Step1:</strong> <strong>簇分配</strong> </p>
<ul>
<li>随机在数据集中选择k（即聚成k个类别）个聚类中心（直接选择数据集中的数据点，这k个点即为初始的簇）；</li>
<li>计算数据集中其余每个点到这k个聚类中心点的距离，将距离每个聚类中心的最近的点分配给这个簇，这便完成了一次簇分配（思考一下：每一次簇分配都会分配一个数据点吗？）</li>
</ul>
<p><strong>Step2: ** **移动聚类中心</strong></p>
<ul>
<li>计算每一个簇的平均值，将该平均值作为该簇新的聚类中心。</li>
</ul>
<p>迭代<strong>Step1</strong> 和<strong>Step2</strong>, 直至聚类中心不再发生变化或达到指定迭代次数。</p>
<p>k-means 算法几乎没涉及到任何高等数学知识，还是比较容易理解的。另外，很容易发现：这和我们以前介绍的有监督学习明显不同：在这里，我们不需要标签数据（打标签通常是一个非常耗费人力的过程），算法自己从数据中学习，自己发现数据中的规律或者模式，极大的减少了人工的参与。这就是机器学习中常说的无监督学习。当然 ，kmeans只是一种比较简单并且普及的聚类算法，聚类算法还是有很多的：比如基于密度的聚类方法DBSCAN、层次聚类算法等</p>
<h2 id="k-means知其然知其所以然"><a href="#k-means知其然知其所以然" class="headerlink" title="k-means知其然知其所以然"></a>k-means知其然知其所以然</h2><p>其实一直没有想过k-means也是有代价函数的，一直以为代价函数是有监督学习算法专属的。k-means直接簇划分，簇类中心移动，迭代就行了，要什么代价函数。这次听NG的机器学习课程才意识到k-means也是有代价函数的，只是这个代价函数和有监督学习刻画真实值与预测值之间的代价不同，k-means的代价函数是<strong>最小化所有数据点与其所关联的聚类中心之间的距离之和</strong>，数学形式如下：</p>
<p>$J(c^{(1)},…,c^{(m)},\mu_1,…,\mu_k) = \frac{1}{m}\sum_{i=1}^m||x^{(i)}-\mu_{c^{(i)}}||^2$  s.t. $1&lt;k&lt;m$</p>
<p>其中 $\mu_{c^{(i)}}$ 表示与 $x^{(i)}$ 最近的聚类中心点，优化目标是找出使得代价函数最小的 $c^{(1)},…,c^{(m)}$ 和$\mu_1,…,\mu_k$ 。但是这里面的最小是指 $k$ 选择了一个特定的值之后最小。不然在极端情况下，每个样本都归属于一个类别，这样代价函数最小，但是没有什么实际意义。</p>
<p>k-means算法中，<strong>Step1</strong> 的簇分配便是为了用于减小c(i)引起的代价（选择距离聚类中心最近的点分配给这个簇类）；<strong>Step2</strong> 的聚类中心计算便是为了用于减小μ(i)引起的代价（还不是很理解）。总之，迭代的过程一定会是每一次迭代都在减小代价函数，不然便是出现了错误。</p>
<p>明白了k-means算法的运行原理后，程序编写起来相对也比较简单。主要实现两个功能：簇分配和聚类中心计算。按照代码编写逻辑：首先确定入参和出参，然后模块拆分，最后模块组合。</p>
<ol>
<li><p>确定入参和出参</p>
<ul>
<li>入参：$m$个没有打标签的数据 ${x_1,x_2,…,x_m}$ ，人工指定 $k$ (划分成 $k$ 类)</li>
<li>出参：$k$ 个类别的数据集合</li>
</ul>
</li>
<li><p>模块拆分</p>
<ul>
<li>簇分类： 可以用一个循环将每个点分配到 $k$ 个簇类，然后用$c^{(1)},…,c^{(m)}$存储与第 $i$ 个数据点最近簇类中心的索引，伪码如下：（也可以用向量化的方式实现）</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i=<span class="number">1</span> to m:</span><br><span class="line">    c(i) = index (<span class="keyword">from</span> <span class="number">1</span> to k) of cluster centroid closest to x(i)</span><br></pre></td></tr></table></figure>

<ul>
<li>簇类中心计算：同样也可以用一个循环实现k个簇类中心的更新，用 $\mu_1,…,\mu_k$ 表示k个聚类中心</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> k=<span class="number">1</span> to K:</span><br><span class="line">    u(k) = mean of points assigned to cluster k</span><br></pre></td></tr></table></figure>
</li>
<li><p>模块组合</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 整体流程</span></span><br><span class="line">选择K个点作为初始质心  </span><br><span class="line">repeat  </span><br><span class="line">    将每个点指派到最近的质心，形成K个簇  </span><br><span class="line">    重新计算每个簇的质心  </span><br><span class="line">until 簇不发生变化或达到最大迭代次数 </span><br><span class="line"></span><br><span class="line"><span class="comment"># μ(1),μ(2),...,μ(k)表示聚类中心，c(1),c(2),...,c(m)来存储与第 𝑖个实例数据最近的聚类中</span></span><br><span class="line">心的索引</span><br><span class="line">Repeat &#123;</span><br><span class="line"><span class="comment"># 用于减小c(i)引起的代价</span></span><br><span class="line"><span class="keyword">for</span> i=<span class="number">1</span> to m:</span><br><span class="line">    c(i) = index (<span class="keyword">from</span> <span class="number">1</span> to k) of cluster centroid closest to x(i)</span><br><span class="line"><span class="comment"># 用于减小μ(i)引起的代价</span></span><br><span class="line"><span class="keyword">for</span> k=<span class="number">1</span> to K:</span><br><span class="line">    u(k) = mean of points assigned to cluster k</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="k-means问题集锦"><a href="#k-means问题集锦" class="headerlink" title="k-means问题集锦"></a>k-means问题集锦</h2><p>以下的<strong>Q&amp;A</strong>涉及到k-means算法中的聚类中心初始化、算法局部最优、聚类k的选择等问题</p>
<p><strong>Q1</strong>： 如何初始化聚类中心？初始化聚类中心的时候有什么需要注意吗</p>
<p><strong>A1</strong>:   直接选择数据中的点做为初始的聚类中心，初始点之间距离应该尽量远</p>
<p><strong>Q2</strong>： k-means 有可能会停留在局部最小值处吗？如何理解这种局部最优？什么情况下会陷在局部最小？可以解决吗？</p>
<p><strong>A2</strong>:  很有可能停留在局部最优处的, k-means的局部最优从工程效果角度来说，就是聚类后各个类别的差距很大，有的类别有大量的数据点（这可能是把几个簇合并成一个簇了），有的类别只有几个，甚至有的类别为0个（这可能是把一个簇拆分成几个簇了）。这种局部最优通常是随机初始化时，初始点之间距离太近导致的。所以为了解决这种问题，通常是将初始中心点设置的远一点，并且可通过多次初始化不同的中心点，多次运行算法，然后选择代价函数较小的最为最终的聚类结果。这种方法在 𝐾较小的时候（ 2–10）还是可行的，但是如果 𝐾较大，这么做也可能不会有明显地改善。</p>
<p><strong>Q3：</strong>如何选择一个合适的聚类数量？</p>
<p><strong>A3：</strong> 没有所谓最好的选择聚类数的方法，通常是需要根据不同的问题，人工进行选择的。基本的准则是认清我们运用k-means算法聚类的动机是什么，然后选择能最好服务于该目的的聚类数。业界常用的一个参考方法是肘部法则，即改变k值，观察代价函数的变化，选择使得代价变化最快的一个k值作为聚类数量</p>
<p><strong>Q4：</strong>如何衡量k-means算法的性能？</p>
<p><strong>A4</strong>:  通常用轮廓系数，定义如下：</p>
<p>$s(i) = \frac{b(i)-a(i)}{max{a(i),b{(i)}}}$</p>
<p>其中 $a(i)$ 表示簇内不相似度，通过计算样本 $x_i$ 到同簇其他样本的平均距离获得，应尽可能小；$b_{ij}$ 表示簇间不相似度，通过计算样本 $x_i$ 到其它簇 $C_j$ 的所有样本的平均距离获得，应尽可能大。轮廓系数 $s(i)$ 值越接近 1表示样本 $i$ 聚类越合理，越接近 -1，表示样本  $i$应该分类到另外的簇中，近似为0，表示样本 $i$ 应该在边界上 ;所有样本的 𝑠(𝑖)的均值被成为聚类结果的轮廓系数。</p>
<p>其它的均一性（精准率）、完整性（召回率）、V-measure和 ARI了解下即可，待需要深入的时候在研究下。</p>
<h2 id="k-means实践"><a href="#k-means实践" class="headerlink" title="k-means实践"></a>k-means实践</h2><p>结合scikit-learn进行</p>
<h2 id="k-means脑洞"><a href="#k-means脑洞" class="headerlink" title="k-means脑洞"></a>k-means脑洞</h2><ul>
<li><strong>客群细分</strong> 储了许多客户的信息，而你希望将他们分成不同的客户群，这样你可以对不同类型的客户分<br>别销售产品或者分别提供更适合的服务。社交网络分析：事实上有许多研究人员正在研究这</li>
<li><strong>社交网络分析</strong> 些信息，比如说：你经常跟哪些人联系，而这些人又经常给哪些人发邮件，由此找到关系密切的人群。因此，这可能需要另一个聚类算法，你希望用它发现社交网络中关系密切的朋友</li>
<li><strong>优化计算机集群</strong> 找到数据中心中哪些计算机经常协作工作，然后重新分配资源，重新布局网络。由此优化数据中心，优化数据通信。</li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>聚类</tag>
      </tags>
  </entry>
</search>
